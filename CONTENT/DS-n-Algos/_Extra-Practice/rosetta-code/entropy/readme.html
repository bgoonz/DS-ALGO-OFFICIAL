<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>readme</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
</head>
<body>
<h1 id="entropy">Entropy</h1>
<p><a href="https://www.freecodecamp.org/learn/coding-interview-prep/rosetta-code/entropy">FCC link</a></p>
<p>Calculate the Shannon entropy H of a given input string.</p>
<p>Given the discreet random variable <span class="math inline"><em>X</em></span> that is a string of <span class="math inline"><em>N</em></span> “symbols” (total characters) consisting of <span class="math inline"><em>n</em></span> different characters (n=2 for binary), the Shannon entropy of X in bits/symbol is:</p>
<p><span class="math inline">$H\_2(X) = -\\sum\_{i=1}^n \\frac{count\_i}{N} \\log\_2 \\left(\\frac{count\_i}{N}\\right)$</span></p>
<p>where <span class="math inline"><em>c</em><em>o</em><em>u</em><em>n</em><em>t</em>_<em>i</em></span> is the count of character <span class="math inline"><em>n</em>_<em>i</em></span>.</p>
</body>
</html>
